{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# Homework08\n",
    "\n",
    "Exercises to practice unsupervised learning with clustering\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Get more practice with the ML flow: encode -> normalize -> train -> evaluate\n",
    "- Understand the tradeoffs of modeling parameters\n",
    "- Develop intuition for different clustering models and when to use them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir\n",
    "from PIL import Image as PImage\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from data_utils import object_from_json_url\n",
    "from data_utils import StandardScaler\n",
    "from data_utils import KMeansClustering, GaussianClustering\n",
    "\n",
    "from image_utils import get_pixels, make_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helmet Sizing\n",
    "\n",
    "### Load Dataset\n",
    "\n",
    "Let's load up the full [ANSUR](https://www.openlab.psu.edu/ansur2/) dataset that we looked at briefly in [Week 02](https://github.com/PSAM-5020-2025S-A/WK02) and then again in [Homework06](https://github.com/PSAM-5020-2025S-A/Homework06).\n",
    "\n",
    "This is the dataset that has anthropometric information about U.S. Army personnel.\n",
    "\n",
    "#### WARNING\n",
    "\n",
    "Like we mentioned in class, this dataset is being used for these exercises due to the level of detail in the dataset and the rigorous process that was used in collecting the data.\n",
    "\n",
    "This is a very specific dataset and should not be used to draw general conclusions about people, bodies, or anything else that is not related to the distribution of physical features of U.S. Army personnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "ANSUR_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025S-A/5020-utils/main/datasets/json/ansur.json\"\n",
    "ansur_data = object_from_json_url(ANSUR_FILE)\n",
    "\n",
    "# Look at first 2 records\n",
    "ansur_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load it into a `DataFrame`, like last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.json_normalize(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning\n",
    "\n",
    "Let's pretend we are designing next-generation helmets with embedded over-the-ear headphones and we want to have a few options for sizes.\n",
    "\n",
    "We could use clustering to see if there is a number of clusters that we can divide our population into, so each size covers a similar portion of the population.\n",
    "\n",
    "We can follow similar steps to regression to create a clustering model that uses features about head and ear sizes:\n",
    "\n",
    "1. Load dataset (done! ðŸŽ‰)\n",
    "2. Encode label features as numbers\n",
    "3. Normalize the data\n",
    "4. Separate the feature variables we want to consider (done below)\n",
    "5. Pick a clustering algorithm\n",
    "6. Determine number of clusters\n",
    "7. Cluster data\n",
    "8. Interpret results\n",
    "\n",
    "For step $5$, it's fine to just pick an algorithm ahead of time to see what happens, but feel free to experiment and plot results for multiple clustering methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Encode non-numerical features\n",
    "\n",
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate the features we want to consider\n",
    "ansur_features = ansur_scaled_df[[\"head.height\", \"head.circumference\", \"ear.length\", \"ear.breadth\", \"ear.protrusion\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Create Clustering model\n",
    "\n",
    "## Run the model(s) on the data\n",
    "\n",
    "## Check errors\n",
    "\n",
    "## Plot clusters as function of 2 or 3 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Which clustering algorithm did you choose?<br>\n",
    "Did you try a different one?<br>\n",
    "Do the clusters make sense ? Do they look balanced ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out how many cluster\n",
    "\n",
    "Experiment with the number of clusters to see if the initial choice makes sense.\n",
    "\n",
    "The [WK08](https://github.com/PSAM-5020-2025S-A/WK08) notebook had a for loop that can be used to plot errors versus number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Plot errors and pick how many cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Based on the graphs of errors versus number of clusters, does it look like we should change the initial number of clusters ?<br>\n",
    "How many clusters should we use ? Why ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revise Number of Clusters.\n",
    "\n",
    "Re-run with the new number of clusters and plot the data in $2D$ or $3D$.\n",
    "\n",
    "This can be the same graph as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Re-run clustering with final number of clusters\n",
    "\n",
    "## Run the model on the training data\n",
    "\n",
    "## Check errors\n",
    "\n",
    "## Plot in 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Do these look better than the original number of clusters?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Organization\n",
    "\n",
    "We have a dataset of about $600$ flower images that we might want to classify by species... eventually.\n",
    "\n",
    "What we want to do first is take a look at all of the images and see what kind of images we have, what kind of colors our flowers have and see if there's any other visual information that could help us classify these images later.\n",
    "\n",
    "We'll see how to use clustering and distances to organize our images by color to create a visualization that we cna use to get to know our dataset.\n",
    "\n",
    "### Load Dataset\n",
    "\n",
    "The following cell downloads the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -qO- https://github.com/PSAM-5020-2025S-A/5020-utils/releases/latest/download/flowers.tar.gz | tar xz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can take a look at a few of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = \"./data/image/flowers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(PImage.open(f\"{IMG_DIR}/00_001.png\"))\n",
    "display(PImage.open(f\"{IMG_DIR}/15_001.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Representative Colors\n",
    "\n",
    "The overall process for organizing our images by color will be something like this:\n",
    "\n",
    "1. Iterate over all files in the `data/image/flowers` directory, open each image file and treat it as a dataset\n",
    "   1. Load image into a `DataFrame` where each pixel is a row and R,G,B values are columns/features\n",
    "   2. Cluster into $2$ - $16$ colors\n",
    "   3. Pick $3$ or $4$ representative colors\n",
    "   4. Store image filenames and their representative colors in a Python object\n",
    "2. Once all images have been processed we can order our dataset by different color characteristics: white to black, red to blue, hue value, brightness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Image\n",
    "\n",
    "Let's step through the process of getting representative colors for one image, and then we can repeat this in a loop to process all of the flower images.\n",
    "\n",
    "#### Open Image\n",
    "\n",
    "The `PIL` library does all the work here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image\n",
    "fname = \"00_001.png\"\n",
    "pimg = PImage.open(f\"{IMG_DIR}/{fname}\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put into `DataFrame`\n",
    "\n",
    "We get the pixels and make a dataset/`DataFrame` out of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into DataFrame\n",
    "pxs = get_pixels(pimg)\n",
    "pxs_df = pd.DataFrame(pxs, columns=[\"R\", \"G\", \"B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster colors\n",
    "\n",
    "Create a clustering object, cluster colors into $8$ clusters with `fit_predict()` and take a look at our color palette (`cluster_centers_`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Create Clustering object\n",
    "\n",
    "# TODO: Cluster by color\n",
    "\n",
    "# TODO: Take a look at the color palette (cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Does anything stand out about the colors?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruct Image\n",
    "\n",
    "Since we're only doing one image for now, let's take a look at the clustering result.\n",
    "\n",
    "This is like in the lecture notebook. We'll start with an empty pixel array and as we iterate through the `DataFrame` of cluster ids we append the corresponding colors to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: create empty pixel array\n",
    "pxs_post = []\n",
    "\n",
    "# TODO: iterate through resulting list of cluster ids\n",
    "\n",
    "# TODO: append corresponding color value to pixel array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the image. If this next cell gives errors about using `float` values in images, just make sure the pixel values that are being appended above are all whole number `int` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(make_image(pxs_post, width=pimg.size[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "How does changing the number of clusters affect the resulting image?<br>Try some lower values like <code>2</code> and <code>4</code>, and also some higher ones like <code>12</code> and <code>16</code>. Take a look at a different image.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick Colors\n",
    "\n",
    "Ok, we have some representative colors for our images. We should keep more than one color, but maybe we don't have to keep $12$.\n",
    "\n",
    "We can use the `value_counts()` function of our `DataFrame` to see how many pixels are represented by each of our cluster colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster ids and pixel counts, ordered by descending counts\n",
    "ccounts = px_clusters_df[\"clusters\"].value_counts()\n",
    "display(ccounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since what we are really trying to do here is get some information about the colors of the flowers present in our images, and given the type of images we have, we can start by assuming that the flower colors will be in the top-$4$ clusters returned by `value_counts()`.\n",
    "\n",
    "We can revisit this assumption later. We might also want to add some filters here to ignore sky and vegetation colors (blues and greens) and only keep flower colors.\n",
    "\n",
    "For now, let's just grab the top-$4$ colors from `value_counts()`, remembering we want to keep their rounded `int` values and not the default `float` values in `cluster_centers_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# List to keep colors for each file\n",
    "file_colors = []\n",
    "\n",
    "# TODO: go through ccounts.index and get corresponding colors for clusters\n",
    "\n",
    "# TODO: add top-3 colors to the file_colors object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(file_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Why might we want to cluster into <code>8</code> or even <code>12</code> colors when in the end we're only keeping <code>4</code>?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate and Cluster\n",
    "\n",
    "We've processed one image, now let's process $600$... for-loops FTW!\n",
    "\n",
    "We'll need to loop through all of the images in our directory and repeat the process above for each one of them.\n",
    "\n",
    "We can create a function that takes a filename as input and returns the top-$4$ colors for that image, or... we can just put all of the clustering logic in the body of a for loop. Whichever is easiest.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all files in the flowers directory\n",
    "flower_files = sorted([f for f in listdir(IMG_DIR) if f.endswith(\".png\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the loop. In the end we want our `file_colors` list to have objects that have a filename and $4$ colors associated with each filename. Something like:\n",
    "\n",
    "```py\n",
    "[\n",
    "  {\n",
    "    \"filename\": \"00_001.png\",\n",
    "    \"colors\": [[12,44,12], [112,144,62],  [12,84,112], [212,144,102]]\n",
    "  },\n",
    "  {\n",
    "    \"filename\": \"00_002.png\",\n",
    "    \"colors\": [[22,24,28], [112,114,122], [128,200,2], [250,240,230]]\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "This can take a while to run (up to a minute for $600$ images). We can use slicing to test our logic on a subset of `flower_files` before processing all $600$ images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# List to keep colors for each file\n",
    "file_colors = []\n",
    "\n",
    "# TODO: get colors for each image\n",
    "for fname in flower_files:\n",
    "  # TODO: add logic here\n",
    "  \n",
    "  # TODO: add filename+colors object to list of objects\n",
    "  file_colors.append({}) # Change this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order Images (almost)\n",
    "\n",
    "We have a list with objects that keep track of filenames and representative colors. We could create a `DataFrame` or csv dataset with these, but let's go ahead and just use this directly in this format.\n",
    "\n",
    "What we want to do is re-order our list of objects, but using a `key` function that takes each object's colors into consideration.\n",
    "\n",
    "We'll look into how to do this dynamically later, but for now let's order our images by something like _brightness_. It's _like_ brightness because what we'll do is measure how close each image is to the white color `(255,255,255)`.\n",
    "\n",
    "We'll need some helper functions first:\n",
    "\n",
    "- `color_distance()`: takes $2$ colors and returns the distance between them\n",
    "- `min_color_distance()`: given a reference color and a list of colors, returns the distance between the reference color and the closest color in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: implement function that returns distance between two colors\n",
    "def color_distance(c0, c1):\n",
    "  # TODO: add logic here\n",
    "  return 0 # TODO: Change this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tests for the `color_distance()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some tests for the color_distance() function\n",
    "print(color_distance([0,0,0], [255,255,255]), \"should be\", 255*3**.5)\n",
    "print(color_distance([0,100,0], [100,100,0]), \"should be\", 100)\n",
    "print(color_distance([55,222,120], [91,51,192]), \"should be\", 189)\n",
    "print(color_distance([147,207,246], [87,57,50]), \"should be\", 254)\n",
    "print(color_distance([12,250,126], [112,10,195]), \"should be\", 269)\n",
    "print(color_distance([106,71,61], [105,136,100]), \"should be\", 75.81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: implement function that returns minimum distance between a reference color and colors from a list\n",
    "def min_color_distance(ref_color, color_list):\n",
    "  # TODO: add logic here\n",
    "  return 0 # TODO: Change this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three tests for the `min_color_distance()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some tests for the color_distance() function\n",
    "print(min_color_distance([0,0,0], [[255,255,255],[0,100,0],[100,100,0],[58,58,58]]), \"should be\", 100)\n",
    "print(min_color_distance([0,0,0], [[255,255,255],[0,100,0],[100,100,0],[58,57,58]]), \"should be\", 99.88)\n",
    "print(min_color_distance([91,51,192], [[147,207,246],[87,57,50],[12,250,126],[112,10,195]]), \"should be\", 46.16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order Images (for real now)\n",
    "\n",
    "Alright. We have a function that can be used to order our images by their distance to a given color.\n",
    "\n",
    "Let's order our images by how close they are to the brightest color `(255,255,255)`. We'll define a `key` function that, given an object from our `file_colors` list, returns how close that image is to the color `(255,255,255)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: implement function that returns how close our image is to the color white\n",
    "def by_bright_dist(A):\n",
    "  # TODO: add logic here\n",
    "  return 0 # TODO: Change this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order the list and write out a `JSON` file with the image order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_colors_sorted = sorted(file_colors, key=by_bright_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_sorted = [A[\"filename\"] for A in file_colors_sorted]\n",
    "\n",
    "with open(\"./data/flower_order.json\", \"w\") as ofp:\n",
    "  json.dump(files_sorted, ofp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Results\n",
    "\n",
    "We can check the results by running a webserver and looking at a simple web page that orders the images according to the resulting `JSON` file from above.\n",
    "\n",
    "We'll make use of the [`Live Server`](https://marketplace.visualstudio.com/items?itemName=ritwickdey.LiveServer) VSCode extension.\n",
    "\n",
    "We can start the server by clicking on the \"_Go Live_\" button towards the right hand side of the bar at the very bottom of our text editor:\n",
    "\n",
    "<img src=\"./imgs/go_live.jpg\" width=\"600px\">\n",
    "\n",
    "Clicking the \"_Go Live_\" button in Codespace should open up a new tab with a plain html navigation view of our repository. Clicking on the `html/` directory should open up a web page with all of the flower images. If not, you can use your Codespace url to try to find the web server address.\n",
    "\n",
    "If your Codespace url is something like:<br>`https://mango-special-giggle-v6v7asd322f7p6.github.dev/`\n",
    "\n",
    "Then, the webserver should be running at:<br>`https://mango-special-giggle-v6v7asd322f7p6-5500.app.github.dev/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review, Contemplate, Experiment\n",
    "\n",
    "Yes, images with white parts are towards the beginning, but the images towards the end aren't necessarily the ones with dark flowers, but are the ones that have all of their representative colors farthest away from white `(255,255,255)`, which includes very saturated colors/images.\n",
    "\n",
    "A couple of interesting experiments here could be:\n",
    "- Decrease the number of clusters or the number of colors kept after clustering.\n",
    "- Use different colors as the reference for the distance functions. For example, create `by_gold_dist()` or `by_purple_dist()` functions to use as the `key` for sorting.\n",
    "- Order the list of cluster colors by [hue](https://stackoverflow.com/questions/23090019/fastest-formula-to-get-hue-from-rgb). This can be a bit tricky to get right because some colors, like white, black and gray, don't have a unique value for hue, but depend on other aspects of the color, like saturation and lightness, to be well-defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: experiment with number of clusters, number of colors, reference colors or hue distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "What did you try ? What happened ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "It's challenging to define a set of functions that will perfectly order our flowers by color without first having to define very specific color values for filtering and corner-cases. At a high-level, we can imagine that this is because color is a $3$-dimensional value, and we're using it to organize our images into a single-dimensional order.\n",
    "\n",
    "The beginning of our ordering is usually pretty good, since there's only one way for a color to be _close_ to our reference color, but the ordering gets less consistent towards the end because there are many different ways for a color to be _far_ from the reference color.\n",
    "\n",
    "Next week we'll see a very powerful technique that, amongst other things, will help us get around this kind of \"_dimensionality mismatch_\"."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "9103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
